---
title: "Assignment V"
author: "Harika Panuganty"
date: "March 5, 2019"
output: html_document
---

### Due Date: Monday March 11, 2019 at 5:59 pm.

## Introduction
We are going to use a simulated two-class data set with 200 observations for training and 100 observations for testing, which includes two features, and in which there is a visible but non-linear separation between the two classes. Use the code below for creating such a dataset.

```{r, echo=TRUE}
rm(list = ls())
library(plyr)
library(dplyr)
library(pROC)
library(caret)


# set a seed
set.seed(1)

# ---- Create a training set ---- #
# create a matrix with 200 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(200*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] -2
# assign class labels
y <- c(rep(1, 150), rep(0, 50))
# this forms a training set
d.train <- data.frame(x = x, y = as.factor(y))
names(d.train) <- c("X1", "X2", "Y")


# ---- Create a test set ---- #
# create a matrix with 100 rows and two colums with values sampled from a normal distribution.
x <- matrix(rnorm(100*2), ncol = 2)
# Introduce some non-linearity where we move points around
x[1:25,] <- x[1:25,] + 2 # moves points to the top-right of a 2D space
x[26:75,] <- x[26:75,] -2 # moves points to the bottom-left of a 2D space
# assign class labels
y <- c(rep(1, 75), rep(0, 25)) 
# this forms a testing set
d.test <- data.frame(x = x, y = as.factor(y))
names(d.test) <- c("X1", "X2", "Y")
```




## Question 1
Create a scatter-plot of all data points in the training set color-labeled by their class type. You will notice that one class is in the center of all points of the other class. In other words, the separation between the classes is a circle around the points with Y as -1. Repeat the same for the testing set. 

```{r}
# Insert your code below

#Scatterplot for train data
plot(x=d.train$X1, y=d.train$X2, type="p", col=d.train$Y, pch=19, cex=1, xlab="X1", ylab="X2", main="Scatterplot for Train Data")

#Scatterplot for test data
plot(x=d.train$X1, y=d.train$X2, type="p", col=d.test$Y, pch=19, cex=1, xlab="X1", ylab="X2", main="Scatterplot for Test Data")


```



## Question 2
Buid a neural network with a variable hidden layer network size from 2 to 50. Feel free to explore different decay rates using "expand.grid" as shown in class. Perform testing on d.test and report the final AUC with 95% CI. 

```{r}
# Insert your code below
library(nnet) 
library(plyr) 
library(dplyr) 
library(pROC) 
library(caret)

#Changing format of Y so it's recognizable to caret package
d.train$Y_cat <- ifelse(d.train$Y == 1, "Yes", "No") 
#d.train <- d.train %>% select(-c(Y))

d.test$Y_cat <- ifelse(d.test$Y == 1, "Yes", "No") 
#d.test <- d.test %>% select(-c(Y))

#Set training parameters to build NN 
fit_control <- trainControl(method = "cv", number = 3,
                           classProbs = TRUE,
                           summaryFunction = twoClassSummary)

#trainControl- controls computational nuances of train fn 
#method- resampling method
#cv- for repeated, training/test splits
#number- no. of folds/no. of resampling iterations 
#classProbs- class probabilities for classification models (+ pred values) in each resample
#summaryFunction- this fn computes metrics across resamples 
#twoClassSummary- metric that relies on class probabilities

#Set of parameters to train over
nnet_params <- expand.grid(size = seq(from = 2, to = 50, by = 1), decay = 5e-4)
head(nnet_params)

#expand.grid-creates a df from all combinations of factor vars 
#from=2 is first net layer; from=50 is second net layer; by=1 means there's one layer from 2-50
#decay 5e-4 is standard for nnets 

#create the model using training data
d.model.train <- train(Y_cat ~ X1+X2, data = d.train,
                 method = "nnet",
                 metric = "ROC",
                 trControl = fit_control,
                 tuneGrid = nnet_params,
               trace = FALSE)

print(d.model.train)

d.model.test <- predict(d.model.train, newdata = d.test, type = "prob") 
head(d.model.test)

d.test$predict_Y <- d.model.test$Yes

#Creating prediction object 
pred_roc <- roc(response=d.test$Y_cat, predictor = d.test$predict_Y, direction= "<") 

#Get AUC performance 
auc_perf <- auc(pred_roc)
cat("AUC: ", auc_perf, "\n")

#Get 95%CI 
ci_auc_perf <- ci.auc(pred_roc)
cat("95% CI: ", ci_auc_perf, "\n")

```



## Question 3

1. Build a logistic regression prediction model using d.train. Test on d.test, and report your test AUC.


```{r}
# Insert your code below
#Logistic regression on dataset
set.seed(345)
d.train.log <- glm(Y ~ X1+X2, data=d.train, family="binomial")

#Perform prediction on test dataset
d.test$pred_Y <- predict.glm(d.train.log, newdata = d.test, type="response")
#we create a new variable, pred_Y1 to avoid above values being overwritten
d.test$pred_Y1 <- ifelse(d.test$pred_Y >= 0.5,1,0)

#For AUC and 95%CI
#Create a prediction object
pred <- roc(response = d.test$Y, predictor = d.test$pred_Y, direction = "<")

#Get AUC performance
auc_log <- auc(pred)
cat("AUC: ", auc_log, "\n")

#AUC 95% CI 
ci_auc_log <- ci.auc(pred)
cat("95% CI: ", ci_auc_log, "\n")

```


2. Which of the two models leads to better performance? Explain in no more than 2 sentences why.        

Ans. The first model, neural network, is better than the logistic regression model. The AUC of the neural network is 0.94 (AUC of 1 is a perfect predictor) while the AUC of the logistic regression is 0.5 (predictor is making random guesses).